{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82853a-79e2-406f-8b63-e3cf401e4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import pyranges as pr\n",
    "from pyranges.pyranges_main import PyRanges\n",
    "\n",
    "from utils import *\n",
    "from peak_parser import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac7e388-9c1a-4603-9e8a-14b5a66eff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# with tf.device('/CPU:0'): \n",
    "      # pass\n",
    "import tensorflow as tf\n",
    "import data_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50810f-ed45-42a0-8109-32d7a2fd6547",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161f35e-8bca-4b66-9263-76fc506d294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "path_peak='data/predicting'\n",
    "cell='MEF'\n",
    "path_cell=path_peak+'/'+cell\n",
    "\n",
    "#MEF\n",
    "atac='SRR5077744_peaks.narrowPeak'\n",
    "h3k27ac='SRR5077641_peaks.narrowPeak'\n",
    "h3k27me3='SRR5077645_peaks.broadPeak'\n",
    "h3k4me1='SRR5077633_peaks.broadPeak'\n",
    "h3k4me3='SRR5077625_peaks.narrowPeak'\n",
    "h3k36me3='SRR5077653_peaks.broadPeak'\n",
    "h3k9me3='SRR5077657_peaks.broadPeak'\n",
    "\n",
    "oh_atac='ATAC.pickle'\n",
    "oh_h3k27ac='H3K27ac.pickle'\n",
    "oh_h3k27me3='H3K27me3.pickle'\n",
    "oh_h3k4me1='H3K4me1.pickle'\n",
    "oh_h3k4me3='H3K4me3.pickle'\n",
    "oh_h3k36me3='H3K36me3.pickle'\n",
    "oh_h3k9me3='H3K9me3.pickle'\n",
    "\n",
    "#\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+atac, path_cell+'/'+oh_atac)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k27ac, path_cell+'/'+oh_h3k27ac)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k27me3, path_cell+'/'+oh_h3k27me3)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k4me1, path_cell+'/'+oh_h3k4me1)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k4me3, path_cell+'/'+oh_h3k4me3)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k36me3, path_cell+'/'+oh_h3k36me3)\n",
    "peak_2onehot_chrom_whole(path_cell+'/'+h3k9me3, path_cell+'/'+oh_h3k9me3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7c3ac-8eab-499c-8fd2-b1e9043b08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract promoter regions (TSS: up-2000bp, down-1000bp)\n",
    "#gtf file was downloaded from https://www.gencodegenes.org/\n",
    "#\n",
    "#zcat gencode.vM25.annotation.gtf.gz | \\\n",
    "#awk 'BEGIN{OFS=FS=\"\\t\"}{if($3==\"gene\") {if($7==\"+\") {start=$4-2000; end=$4+1000;} else {if($7==\"-\") start=$5-1000; end=$5+2000;} if(start<0) start=0; print $1,start,end,$3,$6,$7,$2,$8,$9}}'| \\\n",
    "#grep protein_coding |cut -f 1,2,3|sort|uniq> gencode_vM25_gene_promoter_protein_coding_uniq.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9daad3c-39ca-4689-ba1b-d25629bfe65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract promoter sequence\n",
    "genome_fa_file='data/genome/GRCm38.primary_assembly.genome.fa'  #\n",
    "\n",
    "path_bins='data/genome/windows_mm10/promoter'\n",
    "bed_file=path_bins+'/'+'gencode_vM25_gene_promoter_protein_coding_bins.bed'\n",
    "reg_file=path_bins+'/'+'gencode_vM25_gene_promoter_protein_coding_regs.bed'\n",
    "seq_file=path_bins+'/'+'gene_promoter_bins.fa'\n",
    "\n",
    "extract_fasta(bed_file=bed_file,fa_file=genome_fa_file,seq_file=seq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847f2e28-345a-4dc0-9615-0b3a62357248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "epi_infos=['ATAC', 'H3K27ac', 'H3K27me3', 'H3K36me3', 'H3K4me1', 'H3K4me3', 'H3K9me3']\n",
    "epi_targets=['ATAC', ]\n",
    "\n",
    "tmpdir=path_peak+'/'+'tmp'\n",
    "Path(tmpdir).mkdir(exist_ok=True)  #\n",
    "\n",
    "print('###cell line:', cell)\n",
    "\n",
    "ohpeak_files={'ATAC':path_cell+'/'+'ATAC.pickle',\n",
    "              'H3K27ac':path_cell+'/'+'H3K27ac.pickle',\n",
    "              'H3K27me3':path_cell+'/'+'H3K27me3.pickle',\n",
    "              'H3K36me3':path_cell+'/'+'H3K36me3.pickle',\n",
    "              'H3K4me1':path_cell+'/'+'H3K4me1.pickle',\n",
    "              'H3K4me3':path_cell+'/'+'H3K4me3.pickle',\n",
    "              'H3K9me3':path_cell+'/'+'H3K9me3.pickle'\n",
    "             }\n",
    "\n",
    "bed_file=path_bins+'/'+'gencode_vM25_gene_promoter_protein_coding_bins.bed'\n",
    "reg_file=path_bins+'/'+'gencode_vM25_gene_promoter_protein_coding_regs.bed'\n",
    "seq_file=path_bins+'/'+'gene_promoter_bins.fa'\n",
    "\n",
    "sent_file=path_cell+'/'+'gene_promoter_bins.pickle'\n",
    "n=wc(reg_file)\n",
    "\n",
    "#split file\n",
    "if n>100000:\n",
    "    ns=n//100000+1  #\n",
    "    with open(bed_file,'r') as f:\n",
    "        beds=f.readlines()\n",
    "    with open(reg_file,'r') as f:\n",
    "        regs=f.readlines()\n",
    "    with open(seq_file,'r') as f:\n",
    "        seqs=f.readlines()\n",
    "    for i in range(ns):\n",
    "        sp=i*100000\n",
    "        ep=(i+1)*100000  #\n",
    "        if ep>n:\n",
    "            ep=n\n",
    "        sp_=i*200000\n",
    "        ep_=(i+1)*200000\n",
    "        if ep_>n*2:\n",
    "            ep_=n*2\n",
    "        bed_file_sub=tmpdir+'/'+'gene_promoter_bins_'+str(i)+'.bed'\n",
    "        reg_file_sub=tmpdir+'/'+'gene_promoter_regs_'+str(i)+'.bed'\n",
    "        seq_file_sub=tmpdir+'/'+'gene_promoter_bins_'+str(i)+'.fa'\n",
    "        sent_file_sub=tmpdir+'/'+'gene_promoter_bins_'+str(i)+'.pickle'\n",
    "        with open(bed_file_sub,'w') as f:\n",
    "            f.writelines(beds[sp:ep])\n",
    "        with open(reg_file_sub,'w') as f:\n",
    "            f.writelines(regs[sp:ep])\n",
    "        with open(seq_file_sub,'w') as f:\n",
    "            f.writelines(seqs[sp_:ep_])\n",
    "        \n",
    "        generate_peak_context(seq_file=seq_file_sub,reg_file=reg_file_sub,label=0,targets=epi_infos,targets_files=ohpeak_files,out_file=sent_file_sub,tmpdir=tmpdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fc3813-eca0-4ffd-8f72-33188de8febb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "file_pickles=['gene_promoter_bins_0.pickle',\n",
    "             'gene_promoter_bins_1.pickle',\n",
    "             'gene_promoter_bins_2.pickle',\n",
    "             'gene_promoter_bins_3.pickle',\n",
    "             'gene_promoter_bins_4.pickle',\n",
    "             'gene_promoter_bins_5.pickle',\n",
    "             'gene_promoter_bins_6.pickle',]\n",
    "sent_file=path_cell+'/'+'gene_promoter_bins.pickle'\n",
    "cont_pickles=[]\n",
    "\n",
    "for f in file_pickles:\n",
    "    f2=tmpdir+'/'+f\n",
    "    with open(f2, 'rb') as f:\n",
    "        samples = pickle.load(f)  # [((dna_seq,epi_seq),label),...]\n",
    "    print(len(samples))\n",
    "    cont_pickles.extend(samples)\n",
    "\n",
    "with open(sent_file, 'wb') as f:\n",
    "    pickle.dump(cont_pickles, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7f2798-2b39-416c-905a-d717392ad3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "target_epis=['ATAC',]\n",
    "\n",
    "sent_file_pos=path_cell+'/'+'gene_promoter_bins.pickle'\n",
    "file_set=path_cell+'/'+'gene_promoter_bins.tfrecord'\n",
    "file_set_atac=path_cell+'/'+'gene_promoter_bins_atac.tfrecord'\n",
    "\n",
    "binsset=data_io.select_sample(sample_file=sent_file)\n",
    "print(len(binsset))\n",
    "data_io.write_tfrecord(binsset,file_set)\n",
    "binsset=[mask_peak_context(x,target_epis,keep_dna=True) for x in binsset]\n",
    "data_io.write_tfrecord(binsset,file_set_atac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e8238-dd83-44b6-ba1c-aaf65f0d3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96eed1-9b20-4443-84fd-1c653b950ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "\n",
    "import data_io\n",
    "from data_io import _parse_function\n",
    "\n",
    "from utils import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ec5e8-a629-4cda-b5c7-13504f0aa622",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = 'vocab.txt'\n",
    "tokenizer = text.BertTokenizer(vocab_file, token_out_type=tf.int64)\n",
    "\n",
    "def prepare_batch(example, label):\n",
    "    dna = example[0]\n",
    "    epi = tokenizer.tokenize(example[1])\n",
    "    epi = epi.merge_dims(-2, -1).to_tensor()  #\n",
    "    return (dna, epi), label\n",
    "\n",
    "def make_batches(ds, batch_size=32,buffer_size=20000,shuffle=False,):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    return (\n",
    "        ds\n",
    "        .batch(batch_size)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594b676-e038-4a31-acf7-1e216e2a01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "cell='MEF'\n",
    "tranf='CTCF'\n",
    "\n",
    "path_peak='data/predicting'\n",
    "path_cell=path_peak+'/'+cell\n",
    "path_tf=path_cell+'/'+tranf\n",
    "\n",
    "file_set=path_cell+'/'+'gene_promoter_bins.tfrecord'\n",
    "peak_ds = tf.data.TFRecordDataset([file_set]).map(_parse_function)\n",
    "peak_batches=make_batches(peak_ds,batch_size=128,shuffle=False)  #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79181f1-73da-4653-b468-19c977282bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "vocab_size=3**7\n",
    "d_model = 32\n",
    "len_motif=12\n",
    "dff = 128\n",
    "num_heads = 1\n",
    "num_layers = 1\n",
    "dropout_rate = 0.1\n",
    "\n",
    "epiformer = EIformer(num_layers=num_layers,d_model=d_model,num_heads=num_heads,dff=dff,vocab_size=vocab_size,len_motif=len_motif,dropout_rate=dropout_rate)\n",
    "\n",
    "dna_in=tf.keras.Input((200,4))\n",
    "epi_in=tf.keras.Input((200,))\n",
    "_=epiformer((dna_in,epi_in))\n",
    "\n",
    "epiformer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  #from_logits=True,\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.),]  #\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77a3436-22ce-4549-be62-2ee9e9d4c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "file_weight='models/weights_CTCF.h5'\n",
    "\n",
    "epiformer.load_weights(file_weight)\n",
    "pred_proba = epiformer.predict(x=peak_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73861da-a34a-4c51-bc8a-46fcb46d6c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "path_bins='data/genome/windows_mm10/promoter'\n",
    "file_peak_ori=path_bins+'/'+'gencode_vM25_gene_promoter_protein_coding_bins.bed'\n",
    "print(file_peak_ori)\n",
    "peak_ori=pd.read_csv(file_peak_ori,sep='\\t',header=None)\n",
    "peak_ori[3]=pred_proba\n",
    "\n",
    "file_peak_pred=path_cell+'/'+'pred_sites_'+tranf+'.bed'\n",
    "peak_ori.to_csv(file_peak_pred,sep='\\t',index=False,header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96977d6-2a77-4b99-880e-d79251c407f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
