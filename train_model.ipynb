{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c9f53-9c4c-4eb4-8af3-f6a7ff61cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "\n",
    "import data_io\n",
    "from data_io import _parse_function\n",
    "\n",
    "from utils import *\n",
    "from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ae333-18bd-4ea4-a44a-0a96774257b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU, limiting GPU memory growth\n",
    "#\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaab0ab-c8f2-447d-abee-e6f20ff36c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def prepare_batch(example,label):\n",
    "    dna=example[0]\n",
    "    epi=tokenizer.tokenize(example[1])\n",
    "    epi=epi.merge_dims(-2,-1).to_tensor()  #\n",
    "    return (dna, epi), label\n",
    "\n",
    "def make_batches(ds, batch_size=32,buffer_size=20000,shuffle=False,):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size)\n",
    "    return (\n",
    "        ds\n",
    "        .batch(batch_size)\n",
    "        .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca16c1-b1c6-4b0a-8ab5-4be5733868b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matthews Correlation Coefficient (MCC) metric\n",
    "#\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class MatthewsCorrelationCoefficient(Metric):\n",
    "    def __init__(self, name='matthews_correlation_coefficient', threshold=0.5, **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='true_positives'\n",
    "        )\n",
    "        self.true_negatives = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='true_negatives'\n",
    "        )\n",
    "        self.false_positives = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='false_positives'\n",
    "        )\n",
    "        self.false_negatives = self.add_variable(\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            name='false_negatives'\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None,threshold=0.5):\n",
    "        y_true = tf.cast(y_true, 'bool')\n",
    "        y_pred = tf.cast(y_pred > threshold, 'bool')  # \n",
    "\n",
    "        tp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True)), self.dtype))\n",
    "        tn = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, False)), self.dtype))\n",
    "        fp = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True)), self.dtype))\n",
    "        fn = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, False)), self.dtype))\n",
    "\n",
    "        self.true_positives.assign_add(tp)\n",
    "        self.true_negatives.assign_add(tn)\n",
    "        self.false_positives.assign_add(fp)\n",
    "        self.false_negatives.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        numerator = self.true_positives * self.true_negatives - self.false_positives * self.false_negatives\n",
    "        denominator = tf.sqrt(\n",
    "            (self.true_positives + self.false_positives) *\n",
    "            (self.true_positives + self.false_negatives) *\n",
    "            (self.true_negatives + self.false_positives) *\n",
    "            (self.true_negatives + self.false_negatives)\n",
    "        )\n",
    "        mcc = numerator / (denominator + K.epsilon())  # \n",
    "        return mcc\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.true_positives.assign(0)\n",
    "        self.true_negatives.assign(0)\n",
    "        self.false_positives.assign(0)\n",
    "        self.false_negatives.assign(0)\n",
    "\n",
    "def write_metrics(history,file):\n",
    "    with open(file,'w') as f:\n",
    "        for k,v in history.history.items():\n",
    "            v_new=','.join([str(round(x,4)) for x in v])\n",
    "            line=k+','+v_new+'\\n'\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5351e0-202c-48df-b9bb-5a667eda0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "#\n",
    "cell='GM12878'\n",
    "tranf='CTCF'\n",
    "\n",
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "path_peak='data/training'\n",
    "path_cell=path_peak+'/'+cell\n",
    "path_tf=path_cell+'/'+tranf\n",
    "file_train_set=path_tf+'/'+'train_set.tfrecord'\n",
    "file_test_set=path_tf+'/'+'test_set.tfrecord'\n",
    "\n",
    "vocab_file='data/vocab.txt'\n",
    "tokenizer = text.BertTokenizer(vocab_file, token_out_type=tf.int64)\n",
    "\n",
    "train_ds = tf.data.TFRecordDataset([file_train_set]).map(_parse_function)\n",
    "test_ds = tf.data.TFRecordDataset([file_test_set]).map(_parse_function)\n",
    "\n",
    "train_batches=make_batches(train_ds,shuffle=True)\n",
    "test_batches=make_batches(test_ds,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3422790d-4c26-4138-a1cc-398dbd327f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EIformer\n",
    "seed = 1234\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "vocab_size=3**7\n",
    "d_model = 32\n",
    "len_motif=12\n",
    "dff = 128\n",
    "num_heads = 1\n",
    "num_layers = 1\n",
    "dropout_rate = 0.1\n",
    "epiformer = EIformer(num_layers=num_layers,d_model=d_model,num_heads=num_heads,dff=dff,vocab_size=vocab_size,len_motif=len_motif,dropout_rate=dropout_rate)\n",
    "\n",
    "dna_in=tf.keras.Input((200,4))\n",
    "epi_in=tf.keras.Input((200,))\n",
    "\n",
    "_=epiformer((dna_in,epi_in))\n",
    "epiformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f73099-ec69-49dd-b1ed-e78ec2ebdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and saving model\n",
    "#\n",
    "LEARNING_RATE=0.001\n",
    "# ITERATIONs=10\n",
    "EPOCHs=10\n",
    "\n",
    "current_time=datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "out_dir=cell+'/'+tranf+'/' + current_time\n",
    "checkpoint_dir = 'data/logs/'+out_dir\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+'/'+'model_weights_{epoch:02d}.h5',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "epiformer.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  #\n",
    "                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.),\n",
    "                           tf.keras.metrics.Recall(thresholds=0.),\n",
    "                           tf.keras.metrics.Precision(thresholds=0.),\n",
    "                           tf.keras.metrics.AUC(from_logits=True),\n",
    "                           tf.keras.metrics.AUC(from_logits=True, curve='PR'),\n",
    "                           MatthewsCorrelationCoefficient(threshold=0.)\n",
    "                          ]  #\n",
    "                 )\n",
    "history=epiformer.fit(x=train_batches,\n",
    "                      validation_data=test_batches,\n",
    "                      epochs=EPOCHs,\n",
    "                      callbacks=[cp_callback,],  #tensorboard_callback\n",
    "                      verbose=2,\n",
    "                     )\n",
    "#\n",
    "write_metrics(history,checkpoint_dir+'/model_metrics.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720d79b7-afc1-46b3-a82b-1c4dc04ee1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
